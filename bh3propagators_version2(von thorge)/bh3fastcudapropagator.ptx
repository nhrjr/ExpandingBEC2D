	.version 2.3
	.target sm_20
	.address_size 64
	// compiled with /opt/cuda/open64/lib//be
	// nvopencc 4.0 built on 2011-05-12

	.visible .func _Z8fastpropv ()

	//-----------------------------------------------------------
	// Compiling /tmp/tmpxft_00003e95_00000000-9_bh3fastcudapropagator.cpp3.i (/tmp/ccBI#.LsYQPt)
	//-----------------------------------------------------------

	//-----------------------------------------------------------
	// Options:
	//-----------------------------------------------------------
	//  Target:ptx, ISA:sm_20, Endian:little, Pointer Size:64
	//  -O3	(Optimization level)
	//  -g0	(Debug level)
	//  -m2	(Report advisories)
	//-----------------------------------------------------------

	.file	1	"<command-line>"
	.file	2	"/tmp/tmpxft_00003e95_00000000-8_bh3fastcudapropagator.cudafe2.gpu"
	.file	3	"bh3fastcudapropagator.cu"
	.file	4	"/usr/lib/gcc/x86_64-linux-gnu/4.4.5/include/stddef.h"
	.file	5	"/opt/cuda/bin/../include/crt/device_runtime.h"
	.file	6	"/opt/cuda/bin/../include/host_defines.h"
	.file	7	"/opt/cuda/bin/../include/builtin_types.h"
	.file	8	"/opt/cuda/bin/../include/device_types.h"
	.file	9	"/opt/cuda/bin/../include/driver_types.h"
	.file	10	"/opt/cuda/bin/../include/surface_types.h"
	.file	11	"/opt/cuda/bin/../include/texture_types.h"
	.file	12	"/opt/cuda/bin/../include/vector_types.h"
	.file	13	"/opt/cuda/bin/../include/device_launch_parameters.h"
	.file	14	"/opt/cuda/bin/../include/crt/storage_class.h"
	.file	15	"/usr/include/bits/types.h"
	.file	16	"/usr/include/time.h"
	.file	17	"/opt/cuda/bin/../include/cuComplex.h"
	.file	18	"/opt/cuda/bin/../include/common_functions.h"
	.file	19	"/opt/cuda/bin/../include/math_functions.h"
	.file	20	"/opt/cuda/bin/../include/math_constants.h"
	.file	21	"/opt/cuda/bin/../include/device_functions.h"
	.file	22	"/opt/cuda/bin/../include/sm_11_atomic_functions.h"
	.file	23	"/opt/cuda/bin/../include/sm_12_atomic_functions.h"
	.file	24	"/opt/cuda/bin/../include/sm_13_double_functions.h"
	.file	25	"/opt/cuda/bin/../include/sm_20_atomic_functions.h"
	.file	26	"/opt/cuda/bin/../include/sm_20_intrinsics.h"
	.file	27	"/opt/cuda/bin/../include/surface_functions.h"
	.file	28	"/opt/cuda/bin/../include/texture_fetch_functions.h"
	.file	29	"/opt/cuda/bin/../include/math_functions_dbl_ptx3.h"

	.extern	.shared .align 8 .b8 base[];
	.const .align 16 .b8 kp[6176];

	.visible .func _Z8fastpropv ()
	{
	.reg .u32 %r<24>;
	.reg .u64 %rd<27>;
	.reg .f64 %fd<26>;
	.reg .pred %p<6>;
	.loc	3	67	0
$LDWbegin__Z8fastpropv:
	mov.u64 	%rd1, base;
	.loc	3	69	0
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ntid.x;
	mul.lo.u32 	%r3, %r2, 2;
	cvt.u64.u32 	%rd2, %r1;
	mul.wide.u32 	%rd3, %r1, 8;
	add.u64 	%rd4, %rd1, %rd3;
	add.u32 	%r4, %r3, %r1;
	cvt.u64.u32 	%rd5, %r4;
	mul.wide.u32 	%rd6, %r4, 8;
	add.u64 	%rd7, %rd1, %rd6;
	ld.shared.f64 	%fd1, [%rd4+0];
	st.shared.f64 	[%rd7+0], %fd1;
	.loc	3	70	0
	mul.lo.u32 	%r5, %r2, 3;
	add.u32 	%r6, %r2, %r1;
	cvt.u64.u32 	%rd8, %r6;
	mul.wide.u32 	%rd9, %r6, 8;
	add.u64 	%rd10, %rd1, %rd9;
	add.u32 	%r7, %r5, %r1;
	cvt.u64.u32 	%rd11, %r7;
	mul.wide.u32 	%rd12, %r7, 8;
	add.u64 	%rd13, %rd1, %rd12;
	ld.shared.f64 	%fd2, [%rd10+0];
	st.shared.f64 	[%rd13+0], %fd2;
	.loc	3	71	0
	bar.sync 	0;
	ld.const.s32 	%r8, [kp+6160];
	mov.u32 	%r9, 1;
	setp.lt.s32 	%p1, %r8, %r9;
	@%p1 bra 	$Lt_0_2818;
	mov.s32 	%r10, %r8;
	sub.u32 	%r11, %r2, 1;
	add.s32 	%r12, %r8, 1;
	sub.s32 	%r13, %r1, 1;
	mov.u32 	%r14, 0;
	setp.eq.u32 	%p2, %r1, %r14;
	selp.s32 	%r15, %r11, %r13, %p2;
	mov.s32 	%r16, 0;
	add.s32 	%r17, %r1, 1;
	setp.eq.u32 	%p3, %r11, %r1;
	selp.s32 	%r18, %r16, %r17, %p3;
	cvt.s64.s32 	%rd14, %r15;
	mul.wide.s32 	%rd15, %r15, 8;
	add.u64 	%rd16, %rd1, %rd15;
	cvt.s64.s32 	%rd17, %r18;
	mul.wide.s32 	%rd18, %r18, 8;
	add.u64 	%rd19, %rd1, %rd18;
	add.u32 	%r19, %r15, %r2;
	cvt.u64.u32 	%rd20, %r19;
	mul.wide.u32 	%rd21, %r19, 8;
	add.u64 	%rd22, %rd1, %rd21;
	add.u32 	%r20, %r18, %r2;
	cvt.u64.u32 	%rd23, %r20;
	mul.wide.u32 	%rd24, %r20, 8;
	add.u64 	%rd25, %rd1, %rd24;
	ld.const.f64 	%fd3, [kp+6144];
	mov.s32 	%r21, 1;
	mov.s32 	%r22, %r10;
$Lt_0_3330:
 //<loop> Loop body line 71, nesting depth: 1, estimated iterations: unknown
	.loc	3	89	0
	cvt.rn.f64.s32 	%fd4, %r21;
	div.rn.f64 	%fd5, %fd3, %fd4;
	ld.shared.f64 	%fd6, [%rd19+0];
	ld.shared.f64 	%fd7, [%rd16+0];
	ld.shared.f64 	%fd8, [%rd4+0];
	mov.f64 	%fd9, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd10, %fd8, %fd9, %fd7;
	add.f64 	%fd11, %fd6, %fd10;
	mul.f64 	%fd12, %fd5, %fd11;
	.loc	3	90	0
	ld.shared.f64 	%fd13, [%rd25+0];
	ld.shared.f64 	%fd14, [%rd22+0];
	ld.shared.f64 	%fd15, [%rd10+0];
	mov.f64 	%fd16, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd17, %fd15, %fd16, %fd14;
	add.f64 	%fd18, %fd13, %fd17;
	mul.f64 	%fd19, %fd5, %fd18;
	.loc	3	91	0
	bar.sync 	0;
	.loc	3	92	0
	neg.f64 	%fd20, %fd19;
	st.shared.f64 	[%rd4+0], %fd20;
	.loc	3	93	0
	st.shared.f64 	[%rd10+0], %fd12;
	.loc	3	94	0
	ld.shared.f64 	%fd21, [%rd7+0];
	sub.f64 	%fd22, %fd21, %fd19;
	st.shared.f64 	[%rd7+0], %fd22;
	.loc	3	95	0
	ld.shared.f64 	%fd23, [%rd13+0];
	add.f64 	%fd24, %fd23, %fd12;
	st.shared.f64 	[%rd13+0], %fd24;
	.loc	3	96	0
	bar.sync 	0;
	add.s32 	%r21, %r21, 1;
	setp.ne.s32 	%p4, %r12, %r21;
	@%p4 bra 	$Lt_0_3330;
$Lt_0_2818:
	.loc	3	98	0
	ret;
$LDWend__Z8fastpropv:
	} // _Z8fastpropv

	.entry _Z21short_fast_zpropagateP7double2 (
		.param .u64 __cudaparm__Z21short_fast_zpropagateP7double2_grid)
	{
	.reg .u32 %r<32>;
	.reg .u64 %rd<31>;
	.reg .f64 %fd<30>;
	.reg .pred %p<6>;
	.loc	3	105	0
$LDWbegin__Z21short_fast_zpropagateP7double2:
	mov.u64 	%rd1, base;
	.loc	3	111	0
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r2, %nctaid.y;
	mul.lo.u32 	%r3, %r2, %r1;
	mov.u32 	%r4, %ctaid.y;
	mul.lo.u32 	%r5, %r4, %r1;
	mov.u32 	%r6, %tid.x;
	mov.u32 	%r7, %ctaid.x;
	mul.lo.u32 	%r8, %r7, %r3;
	add.u32 	%r9, %r5, %r8;
	cvt.u64.u32 	%rd2, %r6;
	mul.wide.u32 	%rd3, %r6, 8;
	add.u64 	%rd4, %rd1, %rd3;
	ld.param.u64 	%rd5, [__cudaparm__Z21short_fast_zpropagateP7double2_grid];
	add.u32 	%r10, %r9, %r6;
	cvt.u64.u32 	%rd6, %r10;
	mul.wide.u32 	%rd7, %r10, 16;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.v2.f64 	{%fd1,%fd2}, [%rd8+0];
	st.shared.f64 	[%rd4+0], %fd1;
	.loc	3	112	0
	add.u32 	%r11, %r6, %r1;
	cvt.u64.u32 	%rd9, %r11;
	mul.wide.u32 	%rd10, %r11, 8;
	add.u64 	%rd11, %rd1, %rd10;
	st.shared.f64 	[%rd11+0], %fd2;
	.loc	3	69	0
	mul.lo.u32 	%r12, %r1, 2;
	add.u32 	%r13, %r12, %r6;
	cvt.u64.u32 	%rd12, %r13;
	mul.wide.u32 	%rd13, %r13, 8;
	add.u64 	%rd14, %rd1, %rd13;
	ld.shared.f64 	%fd3, [%rd4+0];
	st.shared.f64 	[%rd14+0], %fd3;
	.loc	3	70	0
	mul.lo.u32 	%r14, %r1, 3;
	add.u32 	%r15, %r14, %r6;
	cvt.u64.u32 	%rd15, %r15;
	mul.wide.u32 	%rd16, %r15, 8;
	add.u64 	%rd17, %rd1, %rd16;
	ld.shared.f64 	%fd4, [%rd11+0];
	st.shared.f64 	[%rd17+0], %fd4;
	.loc	3	71	0
	bar.sync 	0;
	ld.const.s32 	%r16, [kp+6160];
	mov.u32 	%r17, 1;
	setp.lt.s32 	%p1, %r16, %r17;
	@%p1 bra 	$Lt_1_2818;
	mov.s32 	%r18, %r16;
	sub.u32 	%r19, %r1, 1;
	add.s32 	%r20, %r16, 1;
	sub.s32 	%r21, %r6, 1;
	mov.u32 	%r22, 0;
	setp.eq.u32 	%p2, %r6, %r22;
	selp.s32 	%r23, %r19, %r21, %p2;
	mov.s32 	%r24, 0;
	add.s32 	%r25, %r6, 1;
	setp.eq.u32 	%p3, %r19, %r6;
	selp.s32 	%r26, %r24, %r25, %p3;
	cvt.s64.s32 	%rd18, %r23;
	mul.wide.s32 	%rd19, %r23, 8;
	add.u64 	%rd20, %rd1, %rd19;
	cvt.s64.s32 	%rd21, %r26;
	mul.wide.s32 	%rd22, %r26, 8;
	add.u64 	%rd23, %rd1, %rd22;
	add.u32 	%r27, %r23, %r1;
	cvt.u64.u32 	%rd24, %r27;
	mul.wide.u32 	%rd25, %r27, 8;
	add.u64 	%rd26, %rd1, %rd25;
	add.u32 	%r28, %r26, %r1;
	cvt.u64.u32 	%rd27, %r28;
	mul.wide.u32 	%rd28, %r28, 8;
	add.u64 	%rd29, %rd1, %rd28;
	ld.const.f64 	%fd5, [kp+6144];
	mov.s32 	%r29, 1;
	mov.s32 	%r30, %r18;
$Lt_1_3330:
 //<loop> Loop body line 71, nesting depth: 1, estimated iterations: unknown
	.loc	3	89	0
	cvt.rn.f64.s32 	%fd6, %r29;
	div.rn.f64 	%fd7, %fd5, %fd6;
	ld.shared.f64 	%fd8, [%rd23+0];
	ld.shared.f64 	%fd9, [%rd20+0];
	ld.shared.f64 	%fd10, [%rd4+0];
	mov.f64 	%fd11, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd12, %fd10, %fd11, %fd9;
	add.f64 	%fd13, %fd8, %fd12;
	mul.f64 	%fd14, %fd7, %fd13;
	.loc	3	90	0
	ld.shared.f64 	%fd15, [%rd29+0];
	ld.shared.f64 	%fd16, [%rd26+0];
	ld.shared.f64 	%fd17, [%rd11+0];
	mov.f64 	%fd18, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd19, %fd17, %fd18, %fd16;
	add.f64 	%fd20, %fd15, %fd19;
	mul.f64 	%fd21, %fd7, %fd20;
	.loc	3	91	0
	bar.sync 	0;
	.loc	3	92	0
	neg.f64 	%fd22, %fd21;
	st.shared.f64 	[%rd4+0], %fd22;
	.loc	3	93	0
	st.shared.f64 	[%rd11+0], %fd14;
	.loc	3	94	0
	ld.shared.f64 	%fd23, [%rd14+0];
	sub.f64 	%fd24, %fd23, %fd21;
	st.shared.f64 	[%rd14+0], %fd24;
	.loc	3	95	0
	ld.shared.f64 	%fd25, [%rd17+0];
	add.f64 	%fd26, %fd25, %fd14;
	st.shared.f64 	[%rd17+0], %fd26;
	.loc	3	96	0
	bar.sync 	0;
	add.s32 	%r29, %r29, 1;
	setp.ne.s32 	%p4, %r20, %r29;
	@%p4 bra 	$Lt_1_3330;
$Lt_1_2818:
	.loc	3	114	0
	ld.shared.f64 	%fd27, [%rd14+0];
	.loc	3	115	0
	ld.shared.f64 	%fd28, [%rd17+0];
	st.global.v2.f64 	[%rd8+0], {%fd27,%fd28};
	.loc	3	116	0
	exit;
$LDWend__Z21short_fast_zpropagateP7double2:
	} // _Z21short_fast_zpropagateP7double2

	.entry _Z21short_fast_ypropagateP7double2 (
		.param .u64 __cudaparm__Z21short_fast_ypropagateP7double2_grid)
	{
	.reg .u32 %r<32>;
	.reg .u64 %rd<31>;
	.reg .f64 %fd<30>;
	.reg .pred %p<6>;
	.loc	3	118	0
$LDWbegin__Z21short_fast_ypropagateP7double2:
	mov.u64 	%rd1, base;
	.loc	3	124	0
	mov.u32 	%r1, %nctaid.y;
	mov.u32 	%r2, %tid.x;
	mul.lo.u32 	%r3, %r1, %r2;
	mov.u32 	%r4, %ntid.x;
	mul.lo.u32 	%r5, %r4, %r1;
	mov.u32 	%r6, %ctaid.x;
	mul.lo.u32 	%r7, %r6, %r5;
	add.u32 	%r8, %r3, %r7;
	cvt.u64.u32 	%rd2, %r2;
	mul.wide.u32 	%rd3, %r2, 8;
	add.u64 	%rd4, %rd1, %rd3;
	ld.param.u64 	%rd5, [__cudaparm__Z21short_fast_ypropagateP7double2_grid];
	mov.u32 	%r9, %ctaid.y;
	add.u32 	%r10, %r9, %r8;
	cvt.u64.u32 	%rd6, %r10;
	mul.wide.u32 	%rd7, %r10, 16;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.v2.f64 	{%fd1,%fd2}, [%rd8+0];
	st.shared.f64 	[%rd4+0], %fd1;
	.loc	3	125	0
	add.u32 	%r11, %r4, %r2;
	cvt.u64.u32 	%rd9, %r11;
	mul.wide.u32 	%rd10, %r11, 8;
	add.u64 	%rd11, %rd1, %rd10;
	st.shared.f64 	[%rd11+0], %fd2;
	.loc	3	69	0
	mul.lo.u32 	%r12, %r4, 2;
	add.u32 	%r13, %r12, %r2;
	cvt.u64.u32 	%rd12, %r13;
	mul.wide.u32 	%rd13, %r13, 8;
	add.u64 	%rd14, %rd1, %rd13;
	ld.shared.f64 	%fd3, [%rd4+0];
	st.shared.f64 	[%rd14+0], %fd3;
	.loc	3	70	0
	mul.lo.u32 	%r14, %r4, 3;
	add.u32 	%r15, %r14, %r2;
	cvt.u64.u32 	%rd15, %r15;
	mul.wide.u32 	%rd16, %r15, 8;
	add.u64 	%rd17, %rd1, %rd16;
	ld.shared.f64 	%fd4, [%rd11+0];
	st.shared.f64 	[%rd17+0], %fd4;
	.loc	3	71	0
	bar.sync 	0;
	ld.const.s32 	%r16, [kp+6160];
	mov.u32 	%r17, 1;
	setp.lt.s32 	%p1, %r16, %r17;
	@%p1 bra 	$Lt_2_2818;
	mov.s32 	%r18, %r16;
	sub.u32 	%r19, %r4, 1;
	add.s32 	%r20, %r16, 1;
	sub.s32 	%r21, %r2, 1;
	mov.u32 	%r22, 0;
	setp.eq.u32 	%p2, %r2, %r22;
	selp.s32 	%r23, %r19, %r21, %p2;
	mov.s32 	%r24, 0;
	add.s32 	%r25, %r2, 1;
	setp.eq.u32 	%p3, %r19, %r2;
	selp.s32 	%r26, %r24, %r25, %p3;
	cvt.s64.s32 	%rd18, %r23;
	mul.wide.s32 	%rd19, %r23, 8;
	add.u64 	%rd20, %rd1, %rd19;
	cvt.s64.s32 	%rd21, %r26;
	mul.wide.s32 	%rd22, %r26, 8;
	add.u64 	%rd23, %rd1, %rd22;
	add.u32 	%r27, %r23, %r4;
	cvt.u64.u32 	%rd24, %r27;
	mul.wide.u32 	%rd25, %r27, 8;
	add.u64 	%rd26, %rd1, %rd25;
	add.u32 	%r28, %r26, %r4;
	cvt.u64.u32 	%rd27, %r28;
	mul.wide.u32 	%rd28, %r28, 8;
	add.u64 	%rd29, %rd1, %rd28;
	ld.const.f64 	%fd5, [kp+6144];
	mov.s32 	%r29, 1;
	mov.s32 	%r30, %r18;
$Lt_2_3330:
 //<loop> Loop body line 71, nesting depth: 1, estimated iterations: unknown
	.loc	3	89	0
	cvt.rn.f64.s32 	%fd6, %r29;
	div.rn.f64 	%fd7, %fd5, %fd6;
	ld.shared.f64 	%fd8, [%rd23+0];
	ld.shared.f64 	%fd9, [%rd20+0];
	ld.shared.f64 	%fd10, [%rd4+0];
	mov.f64 	%fd11, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd12, %fd10, %fd11, %fd9;
	add.f64 	%fd13, %fd8, %fd12;
	mul.f64 	%fd14, %fd7, %fd13;
	.loc	3	90	0
	ld.shared.f64 	%fd15, [%rd29+0];
	ld.shared.f64 	%fd16, [%rd26+0];
	ld.shared.f64 	%fd17, [%rd11+0];
	mov.f64 	%fd18, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd19, %fd17, %fd18, %fd16;
	add.f64 	%fd20, %fd15, %fd19;
	mul.f64 	%fd21, %fd7, %fd20;
	.loc	3	91	0
	bar.sync 	0;
	.loc	3	92	0
	neg.f64 	%fd22, %fd21;
	st.shared.f64 	[%rd4+0], %fd22;
	.loc	3	93	0
	st.shared.f64 	[%rd11+0], %fd14;
	.loc	3	94	0
	ld.shared.f64 	%fd23, [%rd14+0];
	sub.f64 	%fd24, %fd23, %fd21;
	st.shared.f64 	[%rd14+0], %fd24;
	.loc	3	95	0
	ld.shared.f64 	%fd25, [%rd17+0];
	add.f64 	%fd26, %fd25, %fd14;
	st.shared.f64 	[%rd17+0], %fd26;
	.loc	3	96	0
	bar.sync 	0;
	add.s32 	%r29, %r29, 1;
	setp.ne.s32 	%p4, %r20, %r29;
	@%p4 bra 	$Lt_2_3330;
$Lt_2_2818:
	.loc	3	127	0
	ld.shared.f64 	%fd27, [%rd14+0];
	.loc	3	128	0
	ld.shared.f64 	%fd28, [%rd17+0];
	st.global.v2.f64 	[%rd8+0], {%fd27,%fd28};
	.loc	3	129	0
	exit;
$LDWend__Z21short_fast_ypropagateP7double2:
	} // _Z21short_fast_ypropagateP7double2
	.const .align 8 .b8 __cudart_i2opi_d[144] = {8,93,141,31,177,95,251,107,234,146,82,138,247,57,7,61,123,241,229,235,199,186,39,117,45,234,95,158,102,63,70,79,183,9,203,39,207,126,54,109,31,109,10,90,139,17,47,239,15,152,5,222,255,151,248,31,59,40,249,189,139,95,132,156,244,57,83,131,57,214,145,57,65,126,95,180,38,112,156,233,132,68,187,46,245,53,130,232,62,167,41,177,28,235,29,254,28,146,209,9,234,46,73,6,224,210,77,66,58,110,36,183,97,197,187,222,171,99,81,254,65,144,67,60,153,149,98,219,192,221,52,245,209,87,39,252,41,21,68,78,110,131,249,162};

	.entry _Z21short_fast_xpropagateP7double2 (
		.param .u64 __cudaparm__Z21short_fast_xpropagateP7double2_grid)
	{
	.reg .u32 %r<80>;
	.reg .u64 %rd<94>;
	.reg .f64 %fd<96>;
	.reg .pred %p<19>;
	.local .align 8 .b8 __cuda___cuda_result_486200[40];
	// s = 104
	// c = 96
	// ia = 32
	// hi = 40
	// lo = 88
	.loc	3	131	0
$LDWbegin__Z21short_fast_xpropagateP7double2:
	mov.u64 	%rd1, base;
	.loc	3	137	0
	mov.u32 	%r1, %nctaid.y;
	mov.u32 	%r2, %nctaid.x;
	mul.lo.u32 	%r3, %r2, %r1;
	mov.u32 	%r4, %ctaid.x;
	mul.lo.u32 	%r5, %r4, %r1;
	mov.u32 	%r6, %tid.x;
	mul.lo.u32 	%r7, %r3, %r6;
	add.u32 	%r8, %r5, %r7;
	cvt.u64.u32 	%rd2, %r6;
	mul.wide.u32 	%rd3, %r6, 8;
	add.u64 	%rd4, %rd1, %rd3;
	ld.param.u64 	%rd5, [__cudaparm__Z21short_fast_xpropagateP7double2_grid];
	mov.u32 	%r9, %ctaid.y;
	add.u32 	%r10, %r9, %r8;
	cvt.u64.u32 	%rd6, %r10;
	mul.wide.u32 	%rd7, %r10, 16;
	add.u64 	%rd8, %rd5, %rd7;
	ld.global.v2.f64 	{%fd1,%fd2}, [%rd8+0];
	st.shared.f64 	[%rd4+0], %fd1;
	.loc	3	138	0
	mov.u32 	%r11, %ntid.x;
	add.u32 	%r12, %r11, %r6;
	cvt.u64.u32 	%rd9, %r12;
	mul.wide.u32 	%rd10, %r12, 8;
	add.u64 	%rd11, %rd1, %rd10;
	st.shared.f64 	[%rd11+0], %fd2;
	.loc	3	69	0
	mul.lo.u32 	%r13, %r11, 2;
	add.u32 	%r14, %r13, %r6;
	cvt.u64.u32 	%rd12, %r14;
	mul.wide.u32 	%rd13, %r14, 8;
	add.u64 	%rd14, %rd1, %rd13;
	ld.shared.f64 	%fd3, [%rd4+0];
	st.shared.f64 	[%rd14+0], %fd3;
	.loc	3	70	0
	mul.lo.u32 	%r15, %r11, 3;
	add.u32 	%r16, %r15, %r6;
	cvt.u64.u32 	%rd15, %r16;
	mul.wide.u32 	%rd16, %r16, 8;
	add.u64 	%rd17, %rd1, %rd16;
	ld.shared.f64 	%fd4, [%rd11+0];
	st.shared.f64 	[%rd17+0], %fd4;
	.loc	3	71	0
	bar.sync 	0;
	ld.const.s32 	%r17, [kp+6160];
	mov.u32 	%r18, 1;
	setp.lt.s32 	%p1, %r17, %r18;
	@%p1 bra 	$Lt_3_13314;
	mov.s32 	%r19, %r17;
	sub.u32 	%r20, %r11, 1;
	add.s32 	%r21, %r17, 1;
	sub.s32 	%r22, %r6, 1;
	mov.u32 	%r23, 0;
	setp.eq.u32 	%p2, %r6, %r23;
	selp.s32 	%r24, %r20, %r22, %p2;
	mov.s32 	%r25, 0;
	add.s32 	%r26, %r6, 1;
	setp.eq.u32 	%p3, %r20, %r6;
	selp.s32 	%r27, %r25, %r26, %p3;
	cvt.s64.s32 	%rd18, %r24;
	mul.wide.s32 	%rd19, %r24, 8;
	add.u64 	%rd20, %rd1, %rd19;
	cvt.s64.s32 	%rd21, %r27;
	mul.wide.s32 	%rd22, %r27, 8;
	add.u64 	%rd23, %rd1, %rd22;
	add.u32 	%r28, %r24, %r11;
	cvt.u64.u32 	%rd24, %r28;
	mul.wide.u32 	%rd25, %r28, 8;
	add.u64 	%rd26, %rd1, %rd25;
	add.u32 	%r29, %r27, %r11;
	cvt.u64.u32 	%rd27, %r29;
	mul.wide.u32 	%rd28, %r29, 8;
	add.u64 	%rd29, %rd1, %rd28;
	ld.const.f64 	%fd5, [kp+6144];
	mov.s32 	%r30, 1;
	mov.s32 	%r31, %r19;
$Lt_3_13826:
 //<loop> Loop body line 71, nesting depth: 1, estimated iterations: unknown
	.loc	3	89	0
	cvt.rn.f64.s32 	%fd6, %r30;
	div.rn.f64 	%fd7, %fd5, %fd6;
	ld.shared.f64 	%fd8, [%rd23+0];
	ld.shared.f64 	%fd9, [%rd20+0];
	ld.shared.f64 	%fd10, [%rd4+0];
	mov.f64 	%fd11, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd12, %fd10, %fd11, %fd9;
	add.f64 	%fd13, %fd8, %fd12;
	mul.f64 	%fd14, %fd7, %fd13;
	.loc	3	90	0
	ld.shared.f64 	%fd15, [%rd29+0];
	ld.shared.f64 	%fd16, [%rd26+0];
	ld.shared.f64 	%fd17, [%rd11+0];
	mov.f64 	%fd18, 0dc000000000000000;	// -2
	mad.rn.f64 	%fd19, %fd17, %fd18, %fd16;
	add.f64 	%fd20, %fd15, %fd19;
	mul.f64 	%fd21, %fd7, %fd20;
	.loc	3	91	0
	bar.sync 	0;
	.loc	3	92	0
	neg.f64 	%fd22, %fd21;
	st.shared.f64 	[%rd4+0], %fd22;
	.loc	3	93	0
	st.shared.f64 	[%rd11+0], %fd14;
	.loc	3	94	0
	ld.shared.f64 	%fd23, [%rd14+0];
	sub.f64 	%fd24, %fd23, %fd21;
	st.shared.f64 	[%rd14+0], %fd24;
	.loc	3	95	0
	ld.shared.f64 	%fd25, [%rd17+0];
	add.f64 	%fd26, %fd25, %fd14;
	st.shared.f64 	[%rd17+0], %fd26;
	.loc	3	96	0
	bar.sync 	0;
	add.s32 	%r30, %r30, 1;
	setp.ne.s32 	%p4, %r21, %r30;
	@%p4 bra 	$Lt_3_13826;
$Lt_3_13314:
	.loc	3	143	0
	ld.shared.f64 	%fd27, [%rd14+0];
	.loc	3	144	0
	ld.shared.f64 	%fd28, [%rd17+0];
	.loc	3	149	0
	ld.const.f64 	%fd29, [kp+6152];
	mul.f64 	%fd30, %fd28, %fd28;
	mad.rn.f64 	%fd31, %fd27, %fd27, %fd30;
	mul.f64 	%fd32, %fd29, %fd31;
	.loc	3	150	0
	mov.f64 	%fd33, %fd32;
	.loc	29	490	0
	abs.f64 	%fd34, %fd32;
	mov.f64 	%fd35, 0d7ff0000000000000;	// inf
	setp.eq.f64 	%p5, %fd34, %fd35;
	@!%p5 bra 	$Lt_3_14338;
	.loc	29	491	0
	mov.f64 	%fd36, 0d0000000000000000;	// 0
	mul.rn.f64 	%fd33, %fd32, %fd36;
$Lt_3_14338:
	.loc	29	493	0
	abs.f64 	%fd37, %fd33;
	mov.f64 	%fd38, 0d41e0000000000000;	// 2.14748e+09
	setp.gt.f64 	%p6, %fd37, %fd38;
	@!%p6 bra 	$Lt_3_14850;
	.loc	29	185	0
	mov.b64 	%rd30, %fd33;
	mov.s64 	%rd31, %rd30;
	.loc	29	186	0
	and.b64 	%rd32, %rd30, -9223372036854775808;
	mov.s64 	%rd33, %rd32;
	.loc	29	188	0
	shl.b64 	%rd34, %rd30, 11;
	or.b64 	%rd35, %rd34, -9223372036854775808;
	mov.s64 	%rd36, %rd35;
	.loc	29	191	0
	mov.u64 	%rd37, 0;
	mov.s64 	%rd38, %rd37;
	.loc	29	192	0
	shr.u64 	%rd39, %rd30, 52;
	cvt.u32.u64 	%r32, %rd39;
	and.b32 	%r33, %r32, 2047;
	sub.u32 	%r34, %r33, 1024;
	shr.u32 	%r35, %r34, 6;
	mov.s32 	%r36, 15;
	sub.s32 	%r37, %r36, %r35;
	mov.s32 	%r38, %r37;
	mov.s32 	%r39, 19;
	sub.s32 	%r40, %r39, %r35;
	mov.s32 	%r41, 18;
	min.s32 	%r42, %r40, %r41;
	setp.le.s32 	%p7, %r42, %r37;
	@%p7 bra 	$Lt_3_15362;
	mov.u64 	%rd40, __cuda___cuda_result_486200;
	add.s32 	%r43, %r42, %r35;
	sub.s32 	%r44, %r43, 15;
	mov.u64 	%rd41, __cudart_i2opi_d;
	cvt.s64.s32 	%rd42, %r37;
	mul.wide.s32 	%rd43, %r37, 8;
	add.u64 	%rd44, %rd41, %rd43;
	mov.s32 	%r45, -1;
	sub.s32 	%r46, %r43, 16;
	sub.u64 	%rd45, %rd40, 8;
	mov.s32 	%r47, %r44;
$Lt_3_15874:
	.pragma "nounroll";
 //<loop> Loop body line 192, nesting depth: 1, estimated iterations: unknown
	.loc	29	195	0
	ld.const.u64 	%rd46, [%rd44+0];
	mul.lo.u64 	%rd47, %rd35, %rd46;
	add.u64 	%rd48, %rd47, %rd37;
	mov.s64 	%rd49, %rd48;
	.loc	29	196	0
	set.gt.u32.u64 	%r48, %rd47, %rd48;
	neg.s32 	%r49, %r48;
	cvt.u64.s32 	%rd50, %r49;
	mul.hi.u64 	%rd51, %rd46, %rd35;
	add.u64 	%rd37, %rd50, %rd51;
	mov.s64 	%rd38, %rd37;
	.loc	29	197	0
	st.local.u64 	[%rd45+8], %rd48;
	add.s32 	%r45, %r45, 1;
	add.u64 	%rd45, %rd45, 8;
	add.u64 	%rd44, %rd44, 8;
	setp.ne.s32 	%p8, %r45, %r46;
	@%p8 bra 	$Lt_3_15874;
	mov.s32 	%r38, %r42;
$Lt_3_15362:
	mov.u64 	%rd52, __cuda___cuda_result_486200;
	.loc	29	199	0
	add.s32 	%r50, %r38, %r35;
	sub.s32 	%r51, %r50, 16;
	cvt.s64.s32 	%rd53, %r51;
	mul.wide.s32 	%rd54, %r51, 8;
	add.u64 	%rd55, %rd52, %rd54;
	st.local.u64 	[%rd55+8], %rd37;
	.loc	29	204	0
	ld.local.u64 	%rd37, [__cuda___cuda_result_486200+24];
	mov.s64 	%rd38, %rd37;
	.loc	29	205	0
	ld.local.u64 	%rd56, [__cuda___cuda_result_486200+16];
	mov.s64 	%rd49, %rd56;
	and.b32 	%r52, %r34, 63;
	mov.u32 	%r53, 0;
	setp.eq.u32 	%p9, %r52, %r53;
	@%p9 bra 	$Lt_3_16386;
	.loc	29	208	0
	mov.s32 	%r54, 64;
	sub.s32 	%r55, %r54, %r52;
	shr.u64 	%rd57, %rd56, %r55;
	shl.b64 	%rd58, %rd37, %r52;
	or.b64 	%rd37, %rd57, %rd58;
	mov.s64 	%rd38, %rd37;
	.loc	29	209	0
	ld.local.u64 	%rd59, [__cuda___cuda_result_486200+8];
	shr.u64 	%rd60, %rd59, %r55;
	shl.b64 	%rd61, %rd56, %r52;
	or.b64 	%rd56, %rd60, %rd61;
	mov.s64 	%rd49, %rd56;
$Lt_3_16386:
	.loc	29	211	0
	shr.u64 	%rd62, %rd37, 62;
	cvt.s32.u64 	%r56, %rd62;
	.loc	29	213	0
	shr.u64 	%rd63, %rd56, 62;
	shl.b64 	%rd64, %rd37, 2;
	or.b64 	%rd37, %rd63, %rd64;
	mov.s64 	%rd38, %rd37;
	.loc	29	214	0
	shl.b64 	%rd56, %rd56, 2;
	mov.s64 	%rd49, %rd56;
	.loc	29	216	0
	shr.u64 	%rd65, %rd37, 63;
	cvt.u32.u64 	%r57, %rd65;
	add.u32 	%r58, %r56, %r57;
	.loc	29	211	0
	neg.s32 	%r59, %r58;
	mov.u64 	%rd66, 0;
	setp.ne.u64 	%p10, %rd32, %rd66;
	selp.s32 	%r38, %r59, %r58, %p10;
	mov.u32 	%r60, 0;
	setp.eq.u32 	%p11, %r57, %r60;
	@%p11 bra 	$Lt_3_16898;
	.loc	29	220	0
	not.b64 	%rd67, %rd37;
	mov.s64 	%rd68, %rd67;
	.loc	29	221	0
	mov.s64 	%rd69, %rd49;
	neg.s64 	%rd56, %rd69;
	.loc	29	223	0
	mov.u64 	%rd70, 0;
	set.eq.u32.u64 	%r61, %rd56, %rd70;
	neg.s32 	%r62, %r61;
	cvt.u64.s32 	%rd71, %r62;
	add.u64 	%rd37, %rd71, %rd67;
	mov.s64 	%rd38, %rd37;
	.loc	29	224	0
	xor.b64 	%rd33, %rd32, -9223372036854775808;
$Lt_3_16898:
	.loc	29	226	0
	mov.s32 	%r63, %r38;
	.loc	29	228	0
	mov.s64 	%rd72, %rd38;
	clz.b64 	%r64, %rd72;
	mov.s32 	%r65, %r64;
	.loc	29	226	0
	mov.s32 	%r66, 64;
	sub.s32 	%r67, %r66, %r64;
	shr.u64 	%rd73, %rd56, %r67;
	shl.b64 	%rd74, %rd37, %r64;
	or.b64 	%rd75, %rd73, %rd74;
	mov.u32 	%r68, 0;
	setp.ne.u32 	%p12, %r64, %r68;
	selp.u64 	%rd76, %rd75, %rd37, %p12;
	mov.s64 	%rd77, %rd76;
	.loc	29	232	0
	mul.lo.u64 	%rd56, %rd76, -3958705157555305931;
	.loc	29	233	0
	mov.s64 	%rd78, -3958705157555305931;
	mul.hi.u64 	%rd37, %rd76, %rd78;
	mov.s64 	%rd38, %rd37;
	mov.s64 	%rd79, %rd38;
	mov.u64 	%rd80, 0;
	setp.le.s64 	%p13, %rd79, %rd80;
	@%p13 bra 	$Lt_3_17410;
	.loc	29	235	0
	shr.u64 	%rd81, %rd56, 63;
	shl.b64 	%rd82, %rd37, 1;
	or.b64 	%rd37, %rd81, %rd82;
	mov.s64 	%rd38, %rd37;
	.loc	29	236	0
	add.u32 	%r65, %r64, 1;
$Lt_3_17410:
	.loc	29	238	0
	add.u64 	%rd83, %rd37, 1;
	shr.u64 	%rd84, %rd83, 10;
	add.u64 	%rd85, %rd84, 1;
	shr.u64 	%rd86, %rd85, 1;
	mov.s32 	%r69, 1022;
	sub.s32 	%r70, %r69, %r65;
	cvt.u64.u32 	%rd87, %r70;
	shl.b64 	%rd88, %rd87, 52;
	add.u64 	%rd89, %rd86, %rd88;
	or.b64 	%rd90, %rd33, %rd89;
	mov.s64 	%rd91, %rd90;
	.loc	29	240	0
	mov.s64 	%rd92, %rd91;
	mov.b64 	%fd39, %rd92;
	bra.uni 	$LDWendi___internal_trig_reduction_kerneld_183_1;
$Lt_3_14850:
	.loc	29	252	0
	mov.f64 	%fd40, 0d3fe45f306dc9c883;	// 0.63662
	mul.f64 	%fd41, %fd33, %fd40;
	cvt.rni.s32.f64 	%r71, %fd41;
	mov.s32 	%r63, %r71;
	.loc	29	253	0
	cvt.rn.f64.s32 	%fd42, %r71;
	neg.f64 	%fd43, %fd42;
	mov.f64 	%fd44, 0d397b839a252049c0;	// 8.47843e-32
	mov.f64 	%fd45, 0d3c91a62633145c00;	// 6.12323e-17
	mov.f64 	%fd46, 0d3ff921fb54442d18;	// 1.5708
	mad.rn.f64 	%fd47, %fd43, %fd46, %fd33;
	mad.rn.f64 	%fd48, %fd43, %fd45, %fd47;
	mad.rn.f64 	%fd39, %fd43, %fd44, %fd48;
$LDWendi___internal_trig_reduction_kerneld_183_1:
	.loc	29	283	0
	mov.f64 	%fd49, %fd39;
	mul.f64 	%fd50, %fd49, %fd49;
	mov.f64 	%fd51, 0dbda8ff8d5a8f03db;	// -1.13679e-11
	mov.f64 	%fd52, 0d3e21eea7d67fad92;	// 2.08759e-09
	mad.rn.f64 	%fd53, %fd51, %fd50, %fd52;
	mov.f64 	%fd54, 0dbe927e4f8e26b8e3;	// -2.75573e-07
	mad.rn.f64 	%fd55, %fd53, %fd50, %fd54;
	mov.f64 	%fd56, 0d3efa01a019ddec33;	// 2.48016e-05
	mad.rn.f64 	%fd57, %fd55, %fd50, %fd56;
	mov.f64 	%fd58, 0dbf56c16c16c15d69;	// -0.00138889
	mad.rn.f64 	%fd59, %fd57, %fd50, %fd58;
	mov.f64 	%fd60, 0d3fa5555555555551;	// 0.0416667
	mad.rn.f64 	%fd61, %fd59, %fd50, %fd60;
	mov.f64 	%fd62, 0dbfe0000000000000;	// -0.5
	mad.rn.f64 	%fd63, %fd61, %fd50, %fd62;
	.loc	29	284	0
	mov.f64 	%fd64, 0d3ff0000000000000;	// 1
	mad.rn.f64 	%fd65, %fd63, %fd50, %fd64;
	.loc	29	494	0
	mov.f64 	%fd66, %fd65;
	.loc	29	267	0
	mov.f64 	%fd67, 0d3de5d8fd1fcf0ec1;	// 1.58962e-10
	mov.f64 	%fd68, 0dbe5ae5e5a9291691;	// -2.50507e-08
	mad.rn.f64 	%fd69, %fd67, %fd50, %fd68;
	mov.f64 	%fd70, 0d3ec71de3567d4896;	// 2.75573e-06
	mad.rn.f64 	%fd71, %fd69, %fd50, %fd70;
	mov.f64 	%fd72, 0dbf2a01a019bfdf03;	// -0.000198413
	mad.rn.f64 	%fd73, %fd71, %fd50, %fd72;
	mov.f64 	%fd74, 0d3f8111111110f7d0;	// 0.00833333
	mad.rn.f64 	%fd75, %fd73, %fd50, %fd74;
	mov.f64 	%fd76, 0dbfc5555555555548;	// -0.166667
	mad.rn.f64 	%fd77, %fd75, %fd50, %fd76;
	mul.f64 	%fd78, %fd50, %fd77;
	.loc	29	268	0
	mad.rn.f64 	%fd79, %fd78, %fd49, %fd49;
	.loc	29	495	0
	mov.f64 	%fd80, %fd79;
	.loc	29	496	0
	mov.f64 	%fd81, %fd80;
	and.b32 	%r72, %r63, 1;
	mov.u32 	%r73, 0;
	setp.eq.s32 	%p14, %r72, %r73;
	@%p14 bra 	$Lt_3_17922;
	.loc	29	498	0
	mov.f64 	%fd82, %fd66;
	mov.f64 	%fd80, %fd82;
	.loc	29	499	0
	mov.f64 	%fd66, %fd81;
$Lt_3_17922:
	and.b32 	%r74, %r63, 2;
	mov.u32 	%r75, 0;
	setp.eq.s32 	%p15, %r74, %r75;
	@%p15 bra 	$Lt_3_18434;
	.loc	29	502	0
	mov.f64 	%fd83, %fd80;
	neg.f64 	%fd84, %fd83;
	mov.f64 	%fd80, %fd84;
$Lt_3_18434:
	add.s32 	%r76, %r63, 1;
	and.b32 	%r77, %r76, 2;
	mov.u32 	%r78, 0;
	setp.eq.s32 	%p16, %r77, %r78;
	@%p16 bra 	$Lt_3_18946;
	.loc	29	506	0
	mov.f64 	%fd85, %fd66;
	neg.f64 	%fd86, %fd85;
	mov.f64 	%fd66, %fd86;
$Lt_3_18946:
	mov.f64 	%fd87, 0d0000000000000000;	// 0
	setp.eq.f64 	%p17, %fd49, %fd87;
	@!%p17 bra 	$Lt_3_19458;
	.loc	29	509	0
	mov.f64 	%fd80, %fd49;
$Lt_3_19458:
	.loc	29	511	0
	mov.f64 	%fd88, %fd80;
	.loc	29	512	0
	mov.f64 	%fd89, %fd66;
	.loc	3	151	0
	mul.f64 	%fd90, %fd28, %fd88;
	mul.f64 	%fd91, %fd89, %fd27;
	sub.f64 	%fd92, %fd91, %fd90;
	mul.f64 	%fd93, %fd27, %fd88;
	mad.rn.f64 	%fd94, %fd89, %fd28, %fd93;
	st.global.v2.f64 	[%rd8+0], {%fd92,%fd94};
	.loc	3	152	0
	exit;
$LDWend__Z21short_fast_xpropagateP7double2:
	} // _Z21short_fast_xpropagateP7double2

